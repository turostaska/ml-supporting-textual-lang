import torch.nn as nn
import torch.nn.functional as F
import torch
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import torch.utils.data.DataLoader as DataLoader
import torch.optim.Adam as Adam

class Net: nn.Module {
    val conv1 = nn::Conv2d(1, 32, 3, 1)
    val conv2 = nn::Conv2d(32, 64, 3, 1)
    val dropout1 = nn::Dropout(0.25)
    val dropout2 = nn::Dropout(0.5)
    val fc1 = nn::Linear(9216, 128)
    val fc2 = nn::Linear(128, 10)

    override fun forward(input: Any): Any {
        var x = input
        x = conv1(x)
        x = F::relu(x)
        x = conv2(x)
        x = F::relu(x)
        x = F::max_pool2d(x, 2)
        x = dropout1(x)
        x = torch::flatten(x, 1)
        x = fc1(x)
        x = F::relu(x)
        x = dropout2(x)
        x = fc2(x)
        val output = F::log_softmax(x, dim=1)
        return output
    }
}

val device = torch::device( if (torch::cuda::is_available()) "cuda" else "cpu" )

val batchSize = 8
val lr = 0.0005

val transform = transforms::Compose([
    transforms::ToTensor(),
    transforms::Normalize((0.1307,), (0.3081,)),
])

val dsTrain = datasets::MNIST("../data", train=true, download=true, transform=transform)
val dsTest  = datasets::MNIST("../data", train=false, transform=transform)

val trainLoader = DataLoader(dsTrain, batch_size = batchSize)
val testLoader = DataLoader(dsTest, batch_size = 1)

val model = Net().to(device)
val optimizer = Adam(model.parameters(), lr=lr)

